                cdec cfg './cdec.ini'
Loading the LM will be faster if you build a binary file.
Reading ./nc-wmt11.en.srilm.gz
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
  Example feature: Shape_S00000_T00000
Seeding random number sequence to 4138446869

dtrain
Parameters:
                       k 100
                       N 4
                       T 3
                   batch 0
                  scorer 'fixed_stupid_bleu'
             sample from 'kbest'
                  filter 'uniq'
           learning rate 0.1
                   gamma 0
             loss margin 0
       faster perceptron 1
                   pairs 'XYX'
                   hi lo 0.1
          pair threshold 0
          select weights 'avg'
                  l1 reg 0 'none'
                    pclr no
               max pairs 4294967295
                  repeat 1
                cdec cfg './cdec.ini'
                   input './nc-wmt11.gz'
                  output '-'
              stop_after 10
(a dot represents 10 inputs)
Iteration #1 of 3.
 . 10
Stopping after 10 input sentences.
WEIGHTS
              Glue = -80.3
       WordPenalty = -51.247
     LanguageModel = +282.46
 LanguageModel_OOV = -85.8
     PhraseModel_0 = -100.06
     PhraseModel_1 = -98.692
     PhraseModel_2 = -9.4958
     PhraseModel_3 = +18.535
     PhraseModel_4 = +62.35
     PhraseModel_5 = +7
     PhraseModel_6 = +31.4
       PassThrough = -126.5
        ---
       1best avg score: 0.25631 (+0.25631)
 1best avg model score: -4843.6 (-4843.6)
           avg # pairs: 744.4
        avg # rank err: 0 (meaningless)
     avg # margin viol: 0
       k-best loss imp: 100%
    non0 feature count: 1274
           avg list sz: 91.3
           avg f count: 143.72
(time 0.4 min, 2.4 s/S)

Iteration #2 of 3.
 . 10
WEIGHTS
              Glue = -117.4
       WordPenalty = -99.584
     LanguageModel = +395.05
 LanguageModel_OOV = -136.8
     PhraseModel_0 = +40.614
     PhraseModel_1 = -123.29
     PhraseModel_2 = -152
     PhraseModel_3 = -161.13
     PhraseModel_4 = -76.379
     PhraseModel_5 = +39.1
     PhraseModel_6 = +137.7
       PassThrough = -162.1
        ---
       1best avg score: 0.26751 (+0.011198)
 1best avg model score: -10061 (-5216.9)
           avg # pairs: 639.1
        avg # rank err: 0 (meaningless)
     avg # margin viol: 0
       k-best loss imp: 100%
    non0 feature count: 1845
           avg list sz: 91.3
           avg f count: 139.88
(time 0.35 min, 2.1 s/S)

Iteration #3 of 3.
 . 10
WEIGHTS
              Glue = -101.1
       WordPenalty = -139.97
     LanguageModel = +327.98
 LanguageModel_OOV = -234.7
     PhraseModel_0 = -144.49
     PhraseModel_1 = -263.88
     PhraseModel_2 = -149.25
     PhraseModel_3 = -38.805
     PhraseModel_4 = +50.575
     PhraseModel_5 = -52.4
     PhraseModel_6 = +41.6
       PassThrough = -230.2
        ---
       1best avg score: 0.36222 (+0.094717)
 1best avg model score: -17416 (-7355.5)
           avg # pairs: 661.2
        avg # rank err: 0 (meaningless)
     avg # margin viol: 0
       k-best loss imp: 100%
    non0 feature count: 2163
           avg list sz: 91.3
           avg f count: 132.53
(time 0.33 min, 2 s/S)

Writing weights file to '-' ...
done

---
Best iteration: 3 [SCORE 'fixed_stupid_bleu'=0.36222].
This took 1.0833 min.
